{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crowdsourcing Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll provide a simple walkthrough of how to use Snorkel in conjunction with crowdsourcing to create a training set for a sentiment analysis task.\n",
    "We already have crowdsourced labels for about half of the training dataset.\n",
    "The crowdsourced labels are fairly accurate, but do not cover the entire training dataset, nor are they available for the test set or during inference.\n",
    "To make up for their lack of training set coverage, we combine crowdsourced labels with heuristic labeling functions to increase the number of training labels we have.\n",
    "Like most Snorkel labeling pipelines, we'll use the denoised labels to train a deep learning\n",
    "model which can be applied to new, unseen data to automatically make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll use the [Weather Sentiment](https://data.world/crowdflower/weather-sentiment) dataset from Figure Eight.\n",
    "Our goal is to train a classifier that can label new tweets as expressing either a positive or negative sentiment.\n",
    "\n",
    "Crowdworkers were asked to label the sentiment of a particular tweet relating to the weather.\n",
    "The catch is that 20 crowdworkers graded each tweet, and in many cases crowdworkers assigned conflicting sentiment labels to the same tweet.\n",
    "This is a common issue when dealing with crowdsourced labeling workloads.\n",
    "\n",
    "Label options were positive, negative, or one of three other options saying they weren't sure if it was positive or negative; we use only the positive/negative labels.\n",
    "We've also altered the dataset to reflect a realistic crowdsourcing pipeline where only a subset of our available training set has received crowd labels.\n",
    "\n",
    "We will treat each crowdworker's labels as coming from a single labeling function (LF).\n",
    "This will allow us to learn a weight for how much to trust the labels from each crowdworker.\n",
    "We will also write a few heuristic labeling functions to cover the data points without crowd labels.\n",
    "Snorkel's ability to build high-quality datasets from multiple noisy labeling signals makes it an ideal framework to approach this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Crowdsourcing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading our data which has 287 data points in total.\n",
    "We take 50 for our development set and 50 for our test set.\n",
    "The remaining 187 data points form our training set.\n",
    "Since the dataset is already small, we skip using a validation set.\n",
    "Note that this very small dataset is primarily used for demonstration purposes here.\n",
    "In a real setting, we would expect to have access to many more unlabeled tweets, which could help us to train a higher quality model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Make sure we're in the right directory\n",
    "if os.path.basename(os.getcwd()) == \"snorkel-tutorials\":\n",
    "    os.chdir(\"crowdsourcing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_data\n",
    "\n",
    "crowd_labels, df_train, df_dev, df_test = load_data()\n",
    "Y_dev = df_dev.sentiment.values\n",
    "Y_test = df_test.sentiment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1916, 2), (187, 2), (50, 3), (50, 3))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowd_labels.shape, df_train.shape, df_dev.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(crowd_labels['worker_id'].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "source": [
    "First, let's take a look at our development set to get a sense of what the tweets look like.\n",
    "We use the following label convention: 0 = Negative, 1 = Positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79197834</th>\n",
       "      <td>79197834</td>\n",
       "      <td>@mention not in sunny dover! haha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80059939</th>\n",
       "      <td>80059939</td>\n",
       "      <td>It is literally pissing it down in sideways rain. I have nothing to protect me from this monstrous weather.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79196441</th>\n",
       "      <td>79196441</td>\n",
       "      <td>Dear perfect weather, thanks for the vest lunch hour of all time. (@ Lady Bird Lake Trail w/ 2 others) {link}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84047300</th>\n",
       "      <td>84047300</td>\n",
       "      <td>RT @mention: I can't wait for the storm tonight :)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83255121</th>\n",
       "      <td>83255121</td>\n",
       "      <td>60 degrees. And its almost the end of may. Wisconsin... I hate you.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tweet_id  \\\n",
       "tweet_id             \n",
       "79197834  79197834   \n",
       "80059939  80059939   \n",
       "79196441  79196441   \n",
       "84047300  84047300   \n",
       "83255121  83255121   \n",
       "\n",
       "                                                                                                             tweet_text  \\\n",
       "tweet_id                                                                                                                  \n",
       "79197834  @mention not in sunny dover! haha                                                                               \n",
       "80059939  It is literally pissing it down in sideways rain. I have nothing to protect me from this monstrous weather.     \n",
       "79196441  Dear perfect weather, thanks for the vest lunch hour of all time. (@ Lady Bird Lake Trail w/ 2 others) {link}   \n",
       "84047300  RT @mention: I can't wait for the storm tonight :)                                                              \n",
       "83255121  60 degrees. And its almost the end of may. Wisconsin... I hate you.                                             \n",
       "\n",
       "          sentiment  \n",
       "tweet_id             \n",
       "79197834  1          \n",
       "80059939  0          \n",
       "79196441  1          \n",
       "84047300  1          \n",
       "83255121  0          "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Don't truncate text fields in the display\n",
    "pd.set_option(\"display.max_colwidth\", 0)\n",
    "\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "source": [
    "Now let's take a look at the crowd labels.\n",
    "We'll convert these into labeling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82510997</th>\n",
       "      <td>18034918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82510997</th>\n",
       "      <td>7450342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82510997</th>\n",
       "      <td>18465660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82510997</th>\n",
       "      <td>17475684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82510997</th>\n",
       "      <td>14472526</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          worker_id  label\n",
       "tweet_id                  \n",
       "82510997  18034918   1    \n",
       "82510997  7450342    1    \n",
       "82510997  18465660   1    \n",
       "82510997  17475684   0    \n",
       "82510997  14472526   1    "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowd_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Labeling Functions\n",
    "Each crowdworker can be thought of as a single labeling function,\n",
    "as each worker labels a subset of data points,\n",
    "and may have errors or conflicting labels with other workers / labeling functions.\n",
    "So we create one labeling function per worker.\n",
    "We'll simply return the label the worker submitted for a given tweet, and abstain\n",
    "if they didn't submit a label for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crowdworker labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of workers: 100\n"
     ]
    }
   ],
   "source": [
    "labels_by_annotator = crowd_labels.groupby(\"worker_id\")\n",
    "worker_dicts = {}\n",
    "for worker_id in labels_by_annotator.groups:\n",
    "    worker_df = labels_by_annotator.get_group(worker_id)[[\"label\"]]\n",
    "    worker_dicts[worker_id] = dict(zip(worker_df.index, worker_df.label))\n",
    "\n",
    "print(\"Number of workers:\", len(worker_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LabelingFunction\n",
    "\n",
    "ABSTAIN = -1\n",
    "\n",
    "\n",
    "def worker_lf(x, worker_dict):\n",
    "    return worker_dict.get(x.tweet_id, ABSTAIN)\n",
    "\n",
    "\n",
    "def make_worker_lf(worker_id):\n",
    "    worker_dict = worker_dicts[worker_id]\n",
    "    name = f\"worker_{worker_id}\"\n",
    "    return LabelingFunction(name, f=worker_lf, resources={\"worker_dict\": worker_dict})\n",
    "\n",
    "\n",
    "worker_lfs = [make_worker_lf(worker_id) for worker_id in worker_dicts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at how well they do on the development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 484.78it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 441.99it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "applier = PandasLFApplier(worker_lfs)\n",
    "L_train = applier.apply(df_train)\n",
    "L_dev = applier.apply(df_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that because our dev set is so small and our LFs are relatively sparse, many LFs will appear to have zero coverage.\n",
    "Fortunately, our label model learns weights for LFs based on their outputs on the training set, which is generally much larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>worker_14391185</th>\n",
       "      <td>42</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_7325249</th>\n",
       "      <td>16</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_6344001</th>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_15847995</th>\n",
       "      <td>56</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_11040334</th>\n",
       "      <td>31</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "worker_14391185  42  []       0.00      0.00      0.00       0         \n",
       "worker_7325249   16  [0, 1]   0.22      0.22      0.22       9         \n",
       "worker_6344001   4   [0, 1]   0.08      0.08      0.08       4         \n",
       "worker_15847995  56  [1]      0.02      0.02      0.00       1         \n",
       "worker_11040334  31  [0, 1]   0.16      0.16      0.12       8         \n",
       "\n",
       "                 Incorrect  Emp. Acc.  \n",
       "worker_14391185  0          0.000000   \n",
       "worker_7325249   2          0.818182   \n",
       "worker_6344001   0          1.000000   \n",
       "worker_15847995  0          1.000000   \n",
       "worker_11040334  0          1.000000   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "LFAnalysis(L_dev, worker_lfs).lf_summary(Y_dev).sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the crowd labels in general are quite good! But how much of our dev and training\n",
    "sets do they cover?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set coverage:  50.3%\n",
      "Dev set coverage:  50.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set coverage: {100 * LFAnalysis(L_train).label_coverage(): 0.1f}%\")\n",
    "print(f\"Dev set coverage: {100 * LFAnalysis(L_dev).label_coverage(): 0.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional labeling functions\n",
    "\n",
    "To improve coverage of the training set, we can mix the crowdworker labeling functions with labeling\n",
    "functions of other types.\n",
    "For example, we can use [TextBlob](https://textblob.readthedocs.io/en/dev/index.html), a tool that provides a pretrained sentiment analyzer. We run TextBlob on our tweets and create some simple LFs that threshold its polarity score, similar to what we did in the spam_tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "@preprocessor(memoize=True)\n",
    "def textblob_polarity(x):\n",
    "    scores = TextBlob(x.tweet_text)\n",
    "    x.polarity = scores.polarity\n",
    "    return x\n",
    "\n",
    "\n",
    "# Label high polarity tweets as positive.\n",
    "@labeling_function(pre=[textblob_polarity])\n",
    "def polarity_positive(x):\n",
    "    return 1 if x.polarity > 0.3 else -1\n",
    "\n",
    "\n",
    "# Label low polarity tweets as negative.\n",
    "@labeling_function(pre=[textblob_polarity])\n",
    "def polarity_negative(x):\n",
    "    return 0 if x.polarity < -0.25 else -1\n",
    "\n",
    "\n",
    "# Similar to polarity_negative, but with higher coverage and lower precision.\n",
    "@labeling_function(pre=[textblob_polarity])\n",
    "def polarity_negative_2(x):\n",
    "    return 0 if x.polarity <= 0.3 else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying labeling functions to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 195.09it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 206.16it/s]\n"
     ]
    }
   ],
   "source": [
    "text_lfs = [polarity_positive, polarity_negative, polarity_negative_2]\n",
    "lfs = text_lfs + worker_lfs\n",
    "\n",
    "applier = PandasLFApplier(lfs)\n",
    "L_train = applier.apply(df_train)\n",
    "L_dev = applier.apply(df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>polarity_positive</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity_negative</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity_negative_2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.32</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_6332651</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker_6336109</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "polarity_positive    0  [1]      0.30      0.16      0.12       15        \n",
       "polarity_negative    1  [0]      0.10      0.10      0.04       5         \n",
       "polarity_negative_2  2  [0]      0.70      0.40      0.32       26        \n",
       "worker_6332651       3  [0, 1]   0.06      0.06      0.06       1         \n",
       "worker_6336109       4  []       0.00      0.00      0.00       0         \n",
       "\n",
       "                     Incorrect  Emp. Acc.  \n",
       "polarity_positive    0          1.000000   \n",
       "polarity_negative    0          1.000000   \n",
       "polarity_negative_2  9          0.742857   \n",
       "worker_6332651       2          0.333333   \n",
       "worker_6336109       0          0.000000   "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L_dev, lfs).lf_summary(Y_dev).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the text-based LFs, we've expanded coverage on both our training set\n",
    "and dev set to 100%.\n",
    "We'll now take these noisy and conflicting labels, and use the LabelModel\n",
    "to denoise and combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set coverage:  100.0%\n",
      "Dev set coverage:  100.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set coverage: {100 * LFAnalysis(L_train).label_coverage(): 0.1f}%\")\n",
    "print(f\"Dev set coverage: {100 * LFAnalysis(L_dev).label_coverage(): 0.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LabelModel And Generate Probabilistic Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tibvyasa/miniconda3/envs/snorkel/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/100 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=2.494]\n",
      " 18%|█▊        | 18/100 [00:00<00:03, 23.15epoch/s]INFO:root:[20 epochs]: TRAIN:[loss=0.635]\n",
      " 36%|███▌      | 36/100 [00:01<00:01, 36.86epoch/s]INFO:root:[40 epochs]: TRAIN:[loss=0.605]\n",
      " 57%|█████▋    | 57/100 [00:01<00:00, 74.19epoch/s]INFO:root:[60 epochs]: TRAIN:[loss=0.590]\n",
      " 75%|███████▌  | 75/100 [00:01<00:00, 98.43epoch/s]INFO:root:[80 epochs]: TRAIN:[loss=0.592]\n",
      "100%|██████████| 100/100 [00:01<00:00, 64.80epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "# Train LabelModel.\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train, n_epochs=100, seed=123, log_freq=20, l2=0.1, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a spot-check for the quality of our LabelModel, we'll score it on the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelModel Accuracy: 0.920\n"
     ]
    }
   ],
   "source": [
    "from snorkel.analysis import metric_score\n",
    "\n",
    "preds_dev = label_model.predict(L_dev)\n",
    "\n",
    "acc = metric_score(Y_dev, preds_dev, probs=None, metric=\"accuracy\")\n",
    "print(f\"LabelModel Accuracy: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we get very high accuracy on the development set.\n",
    "This is due to the abundance of high quality crowdworker labels.\n",
    "**Since we don't have these high quality crowdsourcing labels for the\n",
    "test set or new incoming data points, we can't use the LabelModel reliably\n",
    "at inference time.**\n",
    "In order to run inference on new incoming data points, we need to train a\n",
    "discriminative model over the tweets themselves.\n",
    "Let's generate a set of labels for that training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = label_model.predict(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Soft Labels to Train End Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting features from BERT\n",
    "Since we have very limited training data, we cannot train a complex model like an LSTM with a lot of parameters.\n",
    "Instead, we use a pre-trained model, [BERT](https://github.com/google-research/bert), to generate embeddings for each our tweets, and treat the embedding values as features.\n",
    "This may take 5-10 minutes on a CPU, as the BERT model is very large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.modeling_bert:Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "INFO:pytorch_transformers.modeling_xlnet:Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "INFO:pytorch_transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpd_jdzmad\n",
      "100%|██████████| 433/433 [00:00<00:00, 98291.59B/s]\n",
      "INFO:pytorch_transformers.file_utils:copying /tmp/tmpd_jdzmad to cache at /home/tibvyasa/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "INFO:pytorch_transformers.file_utils:creating metadata file for /home/tibvyasa/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "INFO:pytorch_transformers.file_utils:removing temp file /tmp/tmpd_jdzmad\n",
      "INFO:pytorch_transformers.modeling_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/tibvyasa/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "INFO:pytorch_transformers.modeling_utils:Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:pytorch_transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmp47rqcgc2\n",
      "100%|██████████| 440473133/440473133 [01:06<00:00, 6616238.04B/s]\n",
      "INFO:pytorch_transformers.file_utils:copying /tmp/tmp47rqcgc2 to cache at /home/tibvyasa/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "INFO:pytorch_transformers.file_utils:creating metadata file for /home/tibvyasa/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "INFO:pytorch_transformers.file_utils:removing temp file /tmp/tmp47rqcgc2\n",
      "INFO:pytorch_transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/tibvyasa/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "INFO:pytorch_transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp_06h085l\n",
      "100%|██████████| 231508/231508 [00:00<00:00, 539418.58B/s]\n",
      "INFO:pytorch_transformers.file_utils:copying /tmp/tmp_06h085l to cache at /home/tibvyasa/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO:pytorch_transformers.file_utils:creating metadata file for /home/tibvyasa/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO:pytorch_transformers.file_utils:removing temp file /tmp/tmp_06h085l\n",
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/tibvyasa/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_transformers import BertModel, BertTokenizer\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "def encode_text(text):\n",
    "    input_ids = torch.tensor([tokenizer.encode(text)])\n",
    "    return model(input_ids)[0].mean(1)[0].detach().numpy()\n",
    "\n",
    "\n",
    "X_train = np.array(list(df_train.tweet_text.apply(encode_text).values))\n",
    "X_test = np.array(list(df_test.tweet_text.apply(encode_text).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((187, 2), (187, 768))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model on labels\n",
    "Now, we train a simple logistic regression model on the BERT features, using labels\n",
    "obtained from our LabelModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sklearn_model = LogisticRegression(solver=\"liblinear\")\n",
    "sklearn_model.fit(X_train, preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of trained model: 0.86\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of trained model: {sklearn_model.score(X_test, Y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a trained model that can be applied to future data points without requiring crowdsourced labels, and with accuracy not much lower than the `LabelModel` that _does_ have access to crowdsourced labels!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we accomplished the following:\n",
    "* We demonstrated how to combine crowdsourced labels with other programmatic LFs to improve coverage.\n",
    "* We used the `LabelModel` to combine inputs from crowdworkers and other LFs to generate high quality probabilistic labels.\n",
    "* We used our labels to train a classifier for making predictions on new, unseen data points."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
